{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "\n",
    "from wrf import getvar, interplevel, to_np, latlon_coords\n",
    "\n",
    "def read_dataset(input_file):\n",
    "    input_nc = nc.Dataset(input_file)\n",
    "    date = getvar(input_nc,'Times')\n",
    "    time = input_nc.variables['ZNU'].shape[0]\n",
    "    levels = input_nc.variables['ZNU'].shape[1]\n",
    "    \n",
    "    return (input_nc, date, time, levels)\n",
    "\n",
    "def add_noise(variable, noise):\n",
    "    new_variable = variable + noise * np.random.randn(variable.shape[0], variable.shape[1])\n",
    "    return new_variable.astype(dtype='float32')\n",
    "\n",
    "def perturbate_variable(variable, time, levels, noise):\n",
    "    perturbated_variable = np.empty_like(variable)\n",
    "    for hr in range(time):\n",
    "        for lvl in range(levels):\n",
    "            perturbated_variable[hr][lvl] = add_noise(variable[hr][lvl], noise)\n",
    "    return perturbated_variable\n",
    "\n",
    "def perturbate_dataset(input_nc, output_file, noise, time, levels, perturbate_var_func):\n",
    "    output_nc = nc.Dataset(output_file, mode='w')\n",
    "    \n",
    "    # Create the dimensions of the file\n",
    "    for name, dim in input_nc.dimensions.items():\n",
    "        output_nc.createDimension(name, len(dim) if not dim.isunlimited() else None)\n",
    "    \n",
    "    # Copy the global attributes\n",
    "    output_nc.setncatts({ a: input_nc.getncattr(a) for a in input_nc.ncattrs() })\n",
    "    \n",
    "    # Create the variables in the file\n",
    "    for var_name, var in input_nc.variables.items():\n",
    "        output_nc.createVariable(var_name, var.dtype, var.dimensions)\n",
    "\n",
    "        # Copy the variable attributes\n",
    "        output_nc.variables[var_name].setncatts({ a: var.getncattr(a) for a in var.ncattrs()})\n",
    "\n",
    "        # Copy the variables values (as 'f4' eventually)\n",
    "        if var_name in ['U', 'V', 'W', 'P', 'T']:\n",
    "            output_nc.variables[var_name][:] = perturbate_var_func(input_nc.variables[var_name], time, levels, noise)\n",
    "        else:\n",
    "            output_nc.variables[var_name][:] = input_nc.variables[var_name][:]\n",
    "    \n",
    "    # Save and close file\n",
    "    output_nc.close()\n",
    "\n",
    "def generate_ensemble(input_file, output_dir, member_numbers=10, noise=0.01):\n",
    "    input_nc, date, time, levels = read_dataset(input_file)\n",
    "    \n",
    "    for index in range(0, member_numbers):\n",
    "        perturbate_dataset(input_nc, f\"{output_dir}/{index}_wrfout_perturbed.nc\", noise, time, levels, perturbate_variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ensemble('./wrfout.nc', './output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U\n",
      "V\n",
      "W\n",
      "T\n",
      "P\n"
     ]
    }
   ],
   "source": [
    "input_file = './wrfout.nc'\n",
    "output_file = './output/0_wrfout_perturbed.nc'\n",
    "nc_file = nc.Dataset(input_file)\n",
    "nc_file2 = nc.Dataset(output_file)\n",
    "\n",
    "for name in nc_file.variables.keys():\n",
    "    if (nc_file2.variables[name][:]!=nc_file.variables[name][:]).any():\n",
    "        print(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
